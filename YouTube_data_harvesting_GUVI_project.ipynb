{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMJrjpAdMNCWL04lqHVLnq2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sarat143/YouTube_data_harvesting/blob/main/YouTube_data_harvesting_GUVI_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**YouTube data harvesting GUVI project**"
      ],
      "metadata": {
        "id": "WmH4HejSOSwc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##importing the packages to get access"
      ],
      "metadata": {
        "id": "aEfEfKg31IaS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from googleapiclient.discovery import build\n",
        "import pymongo\n",
        "import psycopg2\n",
        "import pandas as pd\n",
        "import streamlit as st"
      ],
      "metadata": {
        "id": "jk3m9M3m1Oyu"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modifying the API key into the Youtube variable and collecting the information"
      ],
      "metadata": {
        "id": "k57MB_hG1YAM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Api_connect():\n",
        "  Api_Id=\"AIzaSyBRuGiiMtUSUsBzR1mjjCCTw_qeJKIszXo\"#API key have a quota limit try to get information form small channels\n",
        "  api_service_name=\"youtube\"\n",
        "  api_version=\"v3\"\n",
        "  youtube=build(api_service_name,api_version,developerKey=Api_Id)\n",
        "\n",
        "  return youtube\n",
        "youtube=Api_connect()"
      ],
      "metadata": {
        "id": "9n9t1Axc1ZPY"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pulling channel information and dictionary file making for MongoDB"
      ],
      "metadata": {
        "id": "4lVxFjwt1b4U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_Channel_info(Channel_Id):\n",
        "  request=youtube.channels().list(\n",
        "              part=\"snippet,ContentDetails,statistics\",\n",
        "              id=Channel_Id\n",
        "  )\n",
        "  response=request.execute()\n",
        "\n",
        "  #dictionary file making\n",
        "\n",
        "  for i in response['items']:\n",
        "    data=dict(Channel_Name=i[\"snippet\"][\"title\"],\n",
        "              Channel_Id=i[\"id\"],\n",
        "              Subcribers=i[\"statistics\"][\"subscriberCount\"],\n",
        "              View=i[\"statistics\"][\"viewCount\"],\n",
        "              Total_Videos=i[\"statistics\"][\"videoCount\"],\n",
        "              Channel_description=i[\"snippet\"][\"description\"],\n",
        "              Playlist_Id=i[\"contentDetails\"][\"relatedPlaylists\"][\"uploads\"])\n",
        "    return data"
      ],
      "metadata": {
        "id": "Cby6m9nJ1d61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pulling channel Video ID's using with channel ID's and dictionary file making for MongoDB"
      ],
      "metadata": {
        "id": "XysYXqit1fRz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_video_Ids(Channel_Id):\n",
        "  video_ids=[]\n",
        "  response=youtube.channels().list(id=Channel_Id,\n",
        "                                  part='contentDetails').execute()\n",
        "  Playlist_Id=response['items'][0]['contentDetails']['relatedPlaylists']['uploads']\n",
        "\n",
        "  #page token used for loop the results get all video' data from channels\n",
        "  next_page_token=None\n",
        "\n",
        "  # max result 50 default is 5 while loop gets all results\n",
        "  while True:\n",
        "    response_of_playlist=youtube.playlistItems().list(\n",
        "                                                  part='snippet',\n",
        "                                                  playlistId=Playlist_Id,\n",
        "                                                  maxResults=50,\n",
        "                                                  pageToken=next_page_token).execute()\n",
        "    for i in range(len(response_of_playlist['items'])):\n",
        "                              video_ids.append(response_of_playlist['items'][i]['snippet']['resourceId']['videoId'])\n",
        "    #getting nextPageToken Id's\n",
        "    next_page_token = response_of_playlist.get('nextPageToken')\n",
        "\n",
        "    if next_page_token is None:#break the loop if all data will received\n",
        "      break\n",
        "  return video_ids"
      ],
      "metadata": {
        "id": "Y94PUF931hZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pulling Channel video information using with Video ID's"
      ],
      "metadata": {
        "id": "R2y2xU_W1jty"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_video_info(video_ids):#use the result of the print value in video ID variable not channel ID\n",
        "        Video_data =[]\n",
        "        for video_id in video_ids:# for loop is used for get all datas of videos and its loops the function\n",
        "                request= youtube.videos().list(\n",
        "                part=\"snippet,ContentDetails,statistics\",\n",
        "                id = video_id\n",
        "                )\n",
        "                response = request.execute()\n",
        "        # For loop the separate specific details of each video\n",
        "                for item in response['items']:\n",
        "                        data=dict(Channel_Name=item['snippet']['channelTitle'],\n",
        "                        Channel_Id=item['snippet']['channelId'],\n",
        "                        Video_Id=item['id'],\n",
        "                        Title=item['snippet']['title'],\n",
        "                        Tags=item['snippet'].get('tags'),\n",
        "                        Thumbnail=item['snippet']['thumbnails']['default']['url'],\n",
        "                        Descriptions=item['snippet'].get('description'),\n",
        "                        Publish_Date=item['snippet']['publishedAt'],\n",
        "                        Duration=item['contentDetails']['duration'],\n",
        "                        Views=item['statistics']['viewCount'],\n",
        "                        likes=item['statistics'].get('likeCount'),\n",
        "                        Comments=item['statistics'].get('commentCount'),\n",
        "                        Favorite_Count=item['statistics']['favoriteCount'],\n",
        "                        Definition=item['contentDetails']['definition'],\n",
        "                        Caption_Status=item['contentDetails']['caption']\n",
        "                        )\n",
        "                Video_data.append(data)\n",
        "        return Video_data # return the video data function is get_video_Info"
      ],
      "metadata": {
        "id": "tC6qvvmg1lxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pulling Channel Comment information using with Video ID's"
      ],
      "metadata": {
        "id": "CMwi28z01n2Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_comment_Info(video_ids):\n",
        "    Comment_data=[]\n",
        "    try:\n",
        "        for video_id in video_ids:# for loop is used for get all datas of videos and its loops the function\n",
        "            request=youtube.commentThreads().list(\n",
        "                part=\"snippet\",\n",
        "                videoId=video_id,\n",
        "                maxResults=50\n",
        "            )\n",
        "            response=request.execute()\n",
        "            # For loop the separate specific details of each video\n",
        "            for item in response['items']:\n",
        "                data=dict(Comment_Id=item['snippet']['topLevelComment']['id'],\n",
        "                          Video_Id=item['snippet']['topLevelComment']['snippet']['videoId'],\n",
        "                          Comment_Text=item['snippet']['topLevelComment']['snippet']['textDisplay'],\n",
        "                          Comment_Author=item['snippet']['topLevelComment']['snippet']['authorDisplayName'],\n",
        "                          Comment_Published=item['snippet']['topLevelComment']['snippet']['publishedAt']\n",
        "                )\n",
        "                Comment_data.append(data)\n",
        "    except:\n",
        "        pass\n",
        "    return Comment_data # return the video data function is get_comment_Info"
      ],
      "metadata": {
        "id": "CI7kzzsg1rev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pulling Channel Play List iformation Using with Video ID's"
      ],
      "metadata": {
        "id": "9DRfg5-c1s7m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_playlist_Info(channel_Id):\n",
        "  #page token used for loop the results get all playlist' data from channels\n",
        "  next_page_token = None\n",
        "  Play_list_data = []\n",
        "  # max result 50 default is 5 while loop gets all results\n",
        "  while True:\n",
        "      request = youtube.playlists().list(\n",
        "          part='snippet,contentDetails',\n",
        "          channelId=channel_Id,\n",
        "          maxResults=50\n",
        "      )\n",
        "      response = request.execute()\n",
        "      for item in response['items']:#slicing the data's\n",
        "          data = dict(Playlist_Id=item['id'],\n",
        "                        Title=item['snippet']['title'],\n",
        "                        Channel_Id=item['snippet']['channelId'],\n",
        "                        Channel_name=item['snippet']['channelTitle'],\n",
        "                        Published_At=item['snippet']['publishedAt'],\n",
        "                        Video_count=item['contentDetails']['itemCount'])\n",
        "          Play_list_data.append(data)\n",
        "      #getting nextPageToken Id's\n",
        "      next_page_token = response.get('nextPageToken')\n",
        "      if next_page_token is None:\n",
        "          break  #break the loop if all data will received\n",
        "  return Play_list_data # return the video data function is get_video_Info"
      ],
      "metadata": {
        "id": "KvQHzVY21vOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Connecting MongoDB and create client data"
      ],
      "metadata": {
        "id": "1f0_YYwf1w1f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client = pymongo.MongoClient(\"mongodb+srv://sarathkumar:kumarsarath@cluster0.rivob1w.mongodb.net/\")\n",
        "\n",
        "db=client[\"youtube_data\"]\n",
        "\n",
        "#define mongoDB cannel information and upload the data to MongoDB\n",
        "def channel_details(channel_Id):\n",
        "    channel_info=get_Channel_info(channel_Id)\n",
        "    playlist_info=get_playlist_Info(channel_Id)\n",
        "    vd_ids=get_video_Ids(channel_Id)\n",
        "    video_info=get_video_info(vd_ids)\n",
        "    comment_info=get_comment_Info(vd_ids)\n",
        "\n",
        "    collection_1=db[\"channel_details\"]\n",
        "    collection_1.insert_one({\"channel_information\":channel_info,\"playlist_information\":playlist_info,\"video_ID's\":vd_ids,\"video_information\":video_info,\"comment_information\":comment_info})\n",
        "\n",
        "    return \"Details fetch successfully\""
      ],
      "metadata": {
        "id": "mp50YKZV1yb7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#PostgresSQL table creation using with channel_details"
      ],
      "metadata": {
        "id": "L-URgoOa118O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def channel_tables(channel_name_s):\n",
        "    mydb=psycopg2.connect(host=\"localhost\",\n",
        "                        user=\"postgres\",\n",
        "                        password=\"kumarsarath\",\n",
        "                        database=\"youtube_data\",\n",
        "                        port=\"5432\")\n",
        "    cursor=mydb.cursor()\n",
        "\n",
        "\n",
        "    # creating a headings of table creations in postgres_sql\n",
        "    create_query='''create table if not exists channels(Channel_Name varchar(100),\n",
        "                                                            Channel_Id varchar(80) primary key,\n",
        "                                                            Subcribers bigint,\n",
        "                                                            View bigint,\n",
        "                                                            Total_Videos int,\n",
        "                                                            Channel_description text,\n",
        "                                                            Playlist_Id varchar(80))'''\n",
        "    cursor.execute(create_query)\n",
        "    mydb.commit()\n",
        "\n",
        "\n",
        "    #using pandas to change the data of youtube entire data into a datafram method and migrate to postgres_sql\n",
        "    list_of_unique_ch=[]\n",
        "    db=client[\"youtube_data\"]\n",
        "    collection_1=db[\"channel_details\"]\n",
        "    for ch_data in collection_1.find({\"channel_information.Channel_Name\": channel_name_s},{\"_id\":0}):\n",
        "        list_of_unique_ch.append(ch_data[\"channel_information\"])\n",
        "\n",
        "    df_list_of_unique_ch= pd.DataFrame(list_of_unique_ch)\n",
        "\n",
        "    # addin information of channel details as row to postgres_sql\n",
        "    for index,row in df_list_of_unique_ch.iterrows():\n",
        "        insert_query='''insert into channels(Channel_Name,\n",
        "                                            Channel_Id,\n",
        "                                            Subcribers,\n",
        "                                            View,\n",
        "                                            Total_Videos,\n",
        "                                            Channel_description,\n",
        "                                            Playlist_Id)\n",
        "\n",
        "                                            values(%s,%s,%s,%s,%s,%s,%s)'''\n",
        "        values=(row['Channel_Name'],\n",
        "                row['Channel_Id'],\n",
        "                row['Subcribers'],\n",
        "                row['View'],\n",
        "                row['Total_Videos'],\n",
        "                row['Channel_description'],\n",
        "                row['Playlist_Id'])\n",
        "\n",
        "        # duplicate error message\n",
        "        try:\n",
        "            cursor.execute(insert_query,values)\n",
        "            mydb.commit()\n",
        "        except:\n",
        "             news=f\"Your provided channel name {channel_name_s} is already exist\"\n",
        "        return news"
      ],
      "metadata": {
        "id": "UpWPFAYc15yy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PostgresSQL table creation"
      ],
      "metadata": {
        "id": "ipAk-Tot2IPm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##PostgresSQL table creation using with playlist_details"
      ],
      "metadata": {
        "id": "gjG8SsYp19wy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def playlist_table(channels_name_s):\n",
        "        mydb=psycopg2.connect(host=\"localhost\",\n",
        "                                user=\"postgres\",\n",
        "                                password=\"kumarsarath\",\n",
        "                                database=\"youtube_data\",\n",
        "                                port=\"5432\")\n",
        "        cursor=mydb.cursor()\n",
        "\n",
        "        # creating a headings of table creations in postgres_sql\n",
        "        create_query='''create table if not exists playlist(Playlist_Id varchar(100)primary key,\n",
        "                                                                Title varchar(80) ,\n",
        "                                                                Channel_Id varchar(100),\n",
        "                                                                Channel_name varchar(100),\n",
        "                                                                Published_At timestamp,\n",
        "                                                                Video_count int)'''\n",
        "        cursor.execute(create_query)\n",
        "        mydb.commit()\n",
        "\n",
        "        #using pandas to change the data of youtube entire data into a datafram method and migrate to postgres_sql\n",
        "        list_of_unique_plst=[]\n",
        "        db=client[\"youtube_data\"]\n",
        "        collection_1=db[\"channel_details\"]\n",
        "        for ch_data in collection_1.find({\"channel_information.Channel_Name\": channels_name_s},{\"_id\":0}):\n",
        "                list_of_unique_plst.append(ch_data[\"playlist_information\"])\n",
        "        df_list_of_unique_plst=pd.DataFrame(list_of_unique_plst[0])\n",
        "\n",
        "        # addin information of playlist details as row to postgres_sql\n",
        "        for index,row in df_list_of_unique_plst.iterrows():\n",
        "                insert_query='''insert into playlist(Playlist_Id,\n",
        "                                                Title,\n",
        "                                                Channel_Id,\n",
        "                                                Channel_name,\n",
        "                                                Published_At,\n",
        "                                                Video_count)\n",
        "\n",
        "                                                values(%s,%s,%s,%s,%s,%s)'''\n",
        "                values=(row['Playlist_Id'],\n",
        "                        row['Title'],\n",
        "                        row['Channel_Id'],\n",
        "                        row['Channel_name'],\n",
        "                        row['Published_At'],\n",
        "                        row['Video_count'])\n",
        "\n",
        "                cursor.execute(insert_query,values)\n",
        "                mydb.commit()"
      ],
      "metadata": {
        "id": "Qi3qZg5E1_y8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##PostgresSQL table creation using with video_details"
      ],
      "metadata": {
        "id": "M8vLVaAD2CMW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def video_table(channels_name_s):\n",
        "    mydb=psycopg2.connect(host=\"localhost\",\n",
        "                                    user=\"postgres\",\n",
        "                                    password=\"kumarsarath\",\n",
        "                                    database=\"youtube_data\",\n",
        "                                    port=\"5432\")\n",
        "    cursor=mydb.cursor()\n",
        "\n",
        "    # creating a headings of table creations in postgres_sql\n",
        "    create_query='''create table if not exists videos(Channel_Name varchar(100),\n",
        "                                                                    Channel_Id varchar(100),\n",
        "                                                                    Video_Id varchar(30) primary key,\n",
        "                                                                    Title varchar(150),\n",
        "                                                                    Tags text,\n",
        "                                                                    Thumbnail varchar(200),\n",
        "                                                                    Descriptions text,\n",
        "                                                                    Publish_Date timestamp,\n",
        "                                                                    Duration interval,\n",
        "                                                                    Views bigint,\n",
        "                                                                    likes bigint,\n",
        "                                                                    Comments int,\n",
        "                                                                    Favorite_Count int,\n",
        "                                                                    Definition varchar(10),\n",
        "                                                                    Caption_Status varchar(50))'''\n",
        "    cursor.execute(create_query)\n",
        "    mydb.commit()\n",
        "\n",
        "    #using pandas to change the data of youtube entire data into a datafram method and migrate to postgres_sql\n",
        "    list_of_unique_vi=[]\n",
        "    db=client[\"youtube_data\"]\n",
        "    collection_1=db[\"channel_details\"]\n",
        "    for ch_data in collection_1.find({\"channel_information.Channel_Name\": channels_name_s},{\"_id\":0}):\n",
        "            list_of_unique_vi.append(ch_data[\"video_information\"])\n",
        "    df_list_of_unique_vi= pd.DataFrame(list_of_unique_vi[0])\n",
        "\n",
        "\n",
        "    # addin information of playlist details as row to postgres_sql\n",
        "    for index,row in df_list_of_unique_vi.iterrows():\n",
        "                    insert_query='''insert into videos(Channel_Name,\n",
        "                                                        Channel_Id,\n",
        "                                                        Video_Id,\n",
        "                                                        Title,\n",
        "                                                        Tags,\n",
        "                                                        Thumbnail,\n",
        "                                                        Descriptions,\n",
        "                                                        Publish_Date,\n",
        "                                                        Duration,\n",
        "                                                        Views,\n",
        "                                                        likes,\n",
        "                                                        Comments,\n",
        "                                                        Favorite_Count,\n",
        "                                                        Definition,\n",
        "                                                        Caption_Status)\n",
        "\n",
        "                                                    values(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)'''\n",
        "                    values=(row['Channel_Name'],\n",
        "                            row['Channel_Id'],\n",
        "                            row['Video_Id'],\n",
        "                            row['Title'],\n",
        "                            row['Tags'],\n",
        "                            row['Thumbnail'],\n",
        "                            row['Descriptions'],\n",
        "                            row['Publish_Date'],\n",
        "                            row['Duration'],\n",
        "                            row['Views'],\n",
        "                            row['likes'],\n",
        "                            row['Comments'],\n",
        "                            row['Favorite_Count'],\n",
        "                            row['Definition'],\n",
        "                            row['Caption_Status'])\n",
        "\n",
        "                    cursor.execute(insert_query,values)\n",
        "                    mydb.commit()"
      ],
      "metadata": {
        "id": "AvIYgGYZ2QeM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##PostgresSQL table creation using with comment_details."
      ],
      "metadata": {
        "id": "_Q-vtcTX2V2U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def comment_table(channels_name_s):\n",
        "    mydb=psycopg2.connect(host=\"localhost\",\n",
        "                                user=\"postgres\",\n",
        "                                password=\"kumarsarath\",\n",
        "                                database=\"youtube_data\",\n",
        "                                port=\"5432\")\n",
        "    cursor=mydb.cursor()\n",
        "\n",
        "    # creating a headings of table creations in postgres_sql\n",
        "    create_query='''create table if not exists comments(Comment_Id varchar(100) primary key,\n",
        "                                                                    Video_Id varchar(50),\n",
        "                                                                    Comment_Text text,\n",
        "                                                                    Comment_Author varchar(150),\n",
        "                                                                    Comment_Published timestamp)'''\n",
        "    cursor.execute(create_query)\n",
        "    mydb.commit()\n",
        "\n",
        "        #using pandas to change the data of youtube entire data into a datafram method and migrate to postgres_sql\n",
        "\n",
        "    list_of_unique_comd=[]\n",
        "    db=client[\"youtube_data\"]\n",
        "    collection_1=db[\"channel_details\"]\n",
        "    for ch_data in collection_1.find({\"channel_information.Channel_Name\": channels_name_s},{\"_id\":0}):\n",
        "                list_of_unique_comd.append(ch_data[\"comment_information\"])\n",
        "\n",
        "    df_list_of_unique_comd= pd.DataFrame(list_of_unique_comd[0])\n",
        "\n",
        "\n",
        "        # addin information of playlist details as row to postgres_sql\n",
        "    for index,row in df_list_of_unique_comd.iterrows():\n",
        "                insert_query='''insert into comments(Comment_Id,\n",
        "                                                     Video_Id,\n",
        "                                                     Comment_Text,\n",
        "                                                     Comment_Author,\n",
        "                                                     Comment_Published)\n",
        "\n",
        "                                                values(%s,%s,%s,%s,%s)'''\n",
        "                values=(row['Comment_Id'],\n",
        "                        row['Video_Id'],\n",
        "                        row['Comment_Text'],\n",
        "                        row['Comment_Author'],\n",
        "                        row['Comment_Published'],\n",
        "                        )\n",
        "\n",
        "                cursor.execute(insert_query,values)\n",
        "                mydb.commit()"
      ],
      "metadata": {
        "id": "aOA-hgK42YvP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## combine all functions into one function"
      ],
      "metadata": {
        "id": "A6PGqfMP2bd1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tables(unique_channels_values):\n",
        "    news=channel_tables(unique_channels_values)\n",
        "    if news:\n",
        "         return news\n",
        "    else:\n",
        "        playlist_table(unique_channels_values)\n",
        "        video_table(unique_channels_values)\n",
        "        comment_table(unique_channels_values)\n",
        "\n",
        "        return \"Tables Created Successfuly\""
      ],
      "metadata": {
        "id": "ftTpyVr52dyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#sending channel information to Stermlit web app"
      ],
      "metadata": {
        "id": "ZshPs5yY2f30"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_channel_tables():\n",
        "    channel_list=[]\n",
        "    db=client[\"youtube_data\"]\n",
        "    collection_1=db[\"channel_details\"]\n",
        "\n",
        "    for ch_data in collection_1.find({},{\"_id\":0,\"channel_information\":1}):\n",
        "        channel_list.append(ch_data[\"channel_information\"])\n",
        "\n",
        "    df=st.dataframe(channel_list)\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "PdqYBFVa2keJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#sending playlist information to Stermlit web app"
      ],
      "metadata": {
        "id": "6QuGj39f2rh7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_playlist_tables():\n",
        "    playlist_list=[]\n",
        "    db=client[\"youtube_data\"]\n",
        "    collection_1=db[\"channel_details\"]\n",
        "\n",
        "    for playlist_data in collection_1.find({},{\"_id\":0,\"playlist_information\":1}):\n",
        "            for i in range(len(playlist_data[\"playlist_information\"])):\n",
        "                    playlist_list.append(playlist_data[\"playlist_information\"][i])\n",
        "\n",
        "    df1 =st.dataframe(playlist_list)\n",
        "\n",
        "    return df1"
      ],
      "metadata": {
        "id": "zkdmV5Mo2vEL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#sending videos information to Stermlit web app"
      ],
      "metadata": {
        "id": "SO0U3HyP2wLc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_videos_tables():\n",
        "    video_list=[]\n",
        "    db=client[\"youtube_data\"]\n",
        "    collection_1=db[\"channel_details\"]\n",
        "\n",
        "    for video_data in collection_1.find({},{\"_id\":0,\"video_information\":1}):\n",
        "        for i in range(len(video_data[\"video_information\"])):\n",
        "            video_list.append(video_data[\"video_information\"][i])\n",
        "\n",
        "    df2 =st.dataframe(video_list)\n",
        "\n",
        "    return df2"
      ],
      "metadata": {
        "id": "JLDbKHLF2y3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#sending comments information to Stermlit web app"
      ],
      "metadata": {
        "id": "K2JTdJQZ20OU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_comments_tables():\n",
        "        comment_list=[]\n",
        "        db=client[\"youtube_data\"]\n",
        "        collection_1=db[\"channel_details\"]\n",
        "\n",
        "        for comment_data in collection_1.find({},{\"_id\":0,\"comment_information\":1}):\n",
        "                for i in range(len(comment_data[\"comment_information\"])):\n",
        "                        comment_list.append(comment_data[\"comment_information\"][i])\n",
        "\n",
        "        df3 =st.dataframe(comment_list)\n",
        "\n",
        "        return df3"
      ],
      "metadata": {
        "id": "GdvFGADU230Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#preparing the stermlit web app"
      ],
      "metadata": {
        "id": "jqooDDsk26oZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with st.sidebar:\n",
        "    st.title(\":green[YouTube Data Harvesting and Warehousing]\")\n",
        "    st.header(\"Skill Take Away\")\n",
        "    st.caption(\"Python Scripting\")\n",
        "    st.caption(\"Data Collection\")\n",
        "    st.caption(\"MongoDB\")\n",
        "    st.caption(\"API Intergration\")\n",
        "    st.caption(\"Data Management using MongoDB and SQL\")\n",
        "\n",
        "channel_id =st.text_input(\"Enter the Channel ID\")\n",
        "\n",
        "if st.button(\"Collect data in MongoDB\"):\n",
        "    ch_id=[]\n",
        "    db=client[\"youtube_data\"]\n",
        "    collection_1=db[\"channel_details\"]\n",
        "    for ch_data in collection_1.find({},{\"_id\":0,\"channel_information\":1}):\n",
        "        ch_id.append(ch_data[\"channel_information\"][\"Channel_Id\"])\n",
        "\n",
        "    if channel_id in ch_id:\n",
        "        st.success(\"Channel details are already provided please try new channel ID\")\n",
        "\n",
        "    else:\n",
        "        insert=channel_details(channel_id)\n",
        "        st.success(insert)\n",
        "\n",
        "all_channels=[]\n",
        "db=client[\"youtube_data\"]\n",
        "collection_1=db[\"channel_details\"]\n",
        "\n",
        "for ch_data in collection_1.find({},{\"_id\":0,\"channel_information\":1}):\n",
        "    all_channels.append(ch_data[\"channel_information\"][\"Channel_Name\"])\n",
        "\n",
        "unique_channel=st.selectbox(\"Select specific channels\",all_channels)\n",
        "\n",
        "if st.button(\"Switch data to SQL\"):\n",
        "    Table=tables(unique_channel)\n",
        "    st.success(Table)\n",
        "\n",
        "show_table=st.radio(\"SELECT THE TABLE FOR VIEW\",(\"CHANNELS\",\"PLAYLISTS\",\"VIDEOS\",\"COMMENTS\"))\n",
        "\n",
        "if show_table==\"CHANNELS\":\n",
        "    show_channel_tables()\n",
        "\n",
        "elif show_table==\"PLAYLISTS\":\n",
        "    show_playlist_tables()\n",
        "\n",
        "elif show_table==\"VIDEOS\":\n",
        "    show_videos_tables()\n",
        "\n",
        "elif show_table==\"COMMENTS\":\n",
        "    show_comments_tables()"
      ],
      "metadata": {
        "id": "-JvPAlis27Pk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#SQL query check and connections"
      ],
      "metadata": {
        "id": "fRG9kSxG2_05"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mydb=psycopg2.connect(host=\"localhost\",\n",
        "                    user=\"postgres\",\n",
        "                    password=\"kumarsarath\",\n",
        "                    database=\"youtube_data\",\n",
        "                    port=\"5432\")\n",
        "cursor=mydb.cursor()\n",
        "\n",
        "questions=st.selectbox(\"Select your questions\",(\"1. What are the names of all the videos and their corresponding channels\",\n",
        "                                                \"2. Which channels have the most number of videos, and how many videos do they have\",\n",
        "                                                \"3. What are the top 10 most viewed videos and their respective channels\",\n",
        "                                                \"4. How many comments were made on each video, and what are their corresponding video names\",\n",
        "                                                \"5. Which videos have the highest number of likes, and what are their corresponding channel names\",\n",
        "                                                \"6. What is the total number of likes and dislikes for each video, and what are their corresponding video names\",\n",
        "                                                \"7. What is the total number of views for each channel, and what are their corresponding channel names\",\n",
        "                                                \"8. What are the names of all the channels that have published videos in the year 2022\",\n",
        "                                                \"9. What is the average duration of all videos in each channel, and what are their corresponding channel names\",\n",
        "                                                \"10. Which videos have the highest number of comments, and what are their corresponding channel names\"))\n",
        "\n",
        "if questions==\"1. What are the names of all the videos and their corresponding channels\":\n",
        "    questions_1 = '''select title as video,channel_name as channelname from videos'''\n",
        "    cursor.execute(questions_1)\n",
        "    mydb.commit()\n",
        "    tabel_1=cursor.fetchall()\n",
        "\n",
        "    df=pd.DataFrame(tabel_1,columns=[\"video title\",\"channel name\"])\n",
        "    st.write(df)\n",
        "\n",
        "elif questions==\"2. Which channels have the most number of videos, and how many videos do they have\":\n",
        "    questions_2 = '''select channel_name as channelname,total_videos as no_videos from channels\n",
        "                    order by total_videos desc'''\n",
        "    cursor.execute(questions_2)\n",
        "    mydb.commit()\n",
        "    tabel_2=cursor.fetchall()\n",
        "\n",
        "    df2=pd.DataFrame(tabel_2,columns=[\"channel name\",\"NO of videos\"])\n",
        "    st.write(df2)\n",
        "\n",
        "elif questions==\"3. What are the top 10 most viewed videos and their respective channels\":\n",
        "    questions_3 = '''select views as views, channel_name as channelname,title as videotile from videos\n",
        "                        where views is not null order by views desc limit 10 '''\n",
        "    cursor.execute(questions_3)\n",
        "    mydb.commit()\n",
        "    tabel_3=cursor.fetchall()\n",
        "\n",
        "    df3=pd.DataFrame(tabel_3,columns=[\"views\",\"channel name\",\"videotitle\"])\n",
        "    st.write(df3)\n",
        "\n",
        "elif questions==\"4. How many comments were made on each video, and what are their corresponding video names\":\n",
        "    questions_4 = '''select comments as no_comments,title as videotitle from videos where comments is not null'''\n",
        "    cursor.execute(questions_4)\n",
        "    mydb.commit()\n",
        "    tabel_4=cursor.fetchall()\n",
        "\n",
        "    df4=pd.DataFrame(tabel_4,columns=[\"no_comments\",\"videotile\"])\n",
        "    st.write(df4)\n",
        "\n",
        "elif questions==\"5. Which videos have the highest number of likes, and what are their corresponding channel names\":\n",
        "    questions_5 = '''select title as videotitle,channel_name as channelname,likes as likecount\n",
        "                        from videos where likes is not null order by likes desc'''\n",
        "    cursor.execute(questions_5)\n",
        "    mydb.commit()\n",
        "    tabel_5=cursor.fetchall()\n",
        "\n",
        "    df5=pd.DataFrame(tabel_5,columns=[\"videotitle\",\"channelname\",\"likecount\"])\n",
        "    st.write(df5)\n",
        "# the Question is get number likes and dislikes in each videos but youtube is hided the dislikes data for community purpose .rate() is not available\n",
        "elif questions==\"6. What is the total number of likes and dislikes for each video, and what are their corresponding video names\":\n",
        "    questions_6 = '''select likes as likecount,title as videotitle from videos'''\n",
        "    cursor.execute(questions_6)\n",
        "    mydb.commit()\n",
        "    tabel_6=cursor.fetchall()\n",
        "\n",
        "    df6=pd.DataFrame(tabel_6,columns=[\"likecount\",\"videotitle\"])\n",
        "    st.write(df6)\n",
        "elif questions==\"7. What is the total number of views for each channel, and what are their corresponding channel names\":\n",
        "    questions_7 = '''select channel_name as channelname,view as totalviews from channels'''\n",
        "    cursor.execute(questions_7)\n",
        "    mydb.commit()\n",
        "    tabel_7=cursor.fetchall()\n",
        "\n",
        "    df7=pd.DataFrame(tabel_7,columns=[\"channelname\",\"totalviews\"])\n",
        "    st.write(df7)\n",
        "elif questions==\"8. What are the names of all the channels that have published videos in the year 2022\":\n",
        "    questions_8 = '''select title as video_title, Publish_Date as videopublished, channel_name as channelname from videos\n",
        "                        where extract(year from Publish_Date)=2022'''\n",
        "    cursor.execute(questions_8)\n",
        "    mydb.commit()\n",
        "    tabel_8=cursor.fetchall()\n",
        "\n",
        "    df8=pd.DataFrame(tabel_8,columns=[\"video_title\",\"videopublished\",\"channelname\"])\n",
        "    st.write(df8)\n",
        "elif questions==\"9. What is the average duration of all videos in each channel, and what are their corresponding channel names\":\n",
        "    questions_9 = '''select channel_name as channelname, AVG(Duration) as avgdurationofvideo from videos group by channel_name'''\n",
        "    cursor.execute(questions_9)\n",
        "    mydb.commit()\n",
        "    tabel_9=cursor.fetchall()\n",
        "\n",
        "    df9=pd.DataFrame(tabel_9,columns=[\"channelname\",\"avgdurationofvideo\"])\n",
        "    # change the avg duration value time format into str format to uploade the data streamlit\n",
        "    Time9=[]\n",
        "    for index,row in df9.iterrows():\n",
        "        channel_titel=row[\"channelname\"]\n",
        "        average_duration=row[\"avgdurationofvideo\"]\n",
        "        average_duration_str=str(average_duration)\n",
        "        Time9.append(dict(channeltitle=channel_titel,avgduration=average_duration_str))\n",
        "    df9_1=pd.DataFrame(Time9)\n",
        "    st.write(df9_1)\n",
        "elif questions==\"10. Which videos have the highest number of comments, and what are their corresponding channel names\":\n",
        "    questions_10 = '''select title as videotitle, channel_name as channelname,comments as comments from videos where comments is not null order by comments desc'''\n",
        "    cursor.execute(questions_10)\n",
        "    mydb.commit()\n",
        "    tabel_10=cursor.fetchall()\n",
        "    df10=pd.DataFrame(tabel_10,columns=[\"videotitle\",\"channelname\",\"comments\"])\n",
        "    st.write(df10)"
      ],
      "metadata": {
        "id": "G7-blFd93D-t"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}